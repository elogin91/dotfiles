"use strict";

exports.__esModule = true;
exports.getSqlDumpDetails = exports.fixMyDumperTransform = exports.SqlDumpType = void 0;
var _nodeFs = _interopRequireDefault(require("node:fs"));
var _nodeReadline = _interopRequireDefault(require("node:readline"));
var _nodeStream = require("node:stream");
var _nodeZlib = _interopRequireDefault(require("node:zlib"));
var _promise = require("./promise");
function _interopRequireDefault(e) { return e && e.__esModule ? e : { default: e }; }
let SqlDumpType = exports.SqlDumpType = /*#__PURE__*/function (SqlDumpType) {
  SqlDumpType["MYDUMPER"] = "MYDUMPER";
  SqlDumpType["MYSQLDUMP"] = "MYSQLDUMP";
  return SqlDumpType;
}({});
const getSqlDumpDetails = async filePath => {
  const isCompressed = filePath.endsWith('.gz');
  let fileStream;
  // eslint-disable-next-line @typescript-eslint/no-invalid-void-type
  const fileStreamExternalPromise = (0, _promise.createExternalizedPromise)();
  if (isCompressed) {
    fileStream = await getSqlFileStreamFromCompressedFile(filePath);
  } else {
    fileStream = _nodeFs.default.createReadStream(filePath);
  }
  const readLine = _nodeReadline.default.createInterface({
    input: fileStream,
    crlfDelay: Infinity
  });
  let isMyDumper = false;
  let sourceDB = '';
  let currentLineNumber = 0;
  for await (const line of readLine) {
    if (line === '') {
      continue;
    }
    const metadataMatch = line.match(/^-- metadata.header /);
    const sourceDBMatch = line.match(/^-- (.*)-schema-create.sql/) ?? [];
    const sourceDBName = sourceDBMatch[1];
    if (metadataMatch && !isMyDumper) {
      isMyDumper = true;
    }
    if (sourceDBMatch && !sourceDB) {
      sourceDB = sourceDBName;
    }
    if (sourceDB && isMyDumper) {
      // all fields found? end the search early.
      break;
    }
    if (currentLineNumber > 100) {
      // we'll assume that this isn't the correct file if we still haven't found `-- metadata.header` even at the 100th line.
      break;
    }
    currentLineNumber++;
  }
  if (fileStream instanceof _nodeFs.default.ReadStream) {
    fileStream.on('close', () => {
      fileStreamExternalPromise.resolve();
    });
  } else {
    fileStreamExternalPromise.resolve();
  }
  readLine.close();
  fileStream.close();
  await fileStreamExternalPromise.promise;
  return {
    type: isMyDumper ? SqlDumpType.MYDUMPER : SqlDumpType.MYSQLDUMP,
    sourceDb: sourceDB
  };
};
exports.getSqlDumpDetails = getSqlDumpDetails;
const verifyFileExists = async filePath => {
  try {
    await _nodeFs.default.promises.access(filePath, _nodeFs.default.constants.F_OK);
  } catch {
    throw new Error('File not accessible. Does file exist?');
  }
};
const getSqlFileStreamFromGz = async filePath => {
  await verifyFileExists(filePath);
  return _nodeFs.default.createReadStream(filePath).pipe(_nodeZlib.default.createGunzip());
};
const getSqlFileStreamFromCompressedFile = async filePath => {
  if (filePath.endsWith('.gz')) {
    return await getSqlFileStreamFromGz(filePath);
  }
  throw new Error('Not a supported compressed file');
};
const fixMyDumperTransform = () => {
  return new _nodeStream.Transform({
    transform(chunk, _encoding, callback) {
      const chunkString = chunk.toString();
      const lineEnding = chunkString.includes('\r\n') ? '\r\n' : '\n';
      const regex = /^-- ([^ ]+) [0-9]+$/;
      const lines = chunk.toString().split(lineEnding).map(line => {
        const match = line.match(regex);
        if (!match) {
          return line;
        }
        const tablePart = match[1];
        return `-- ${tablePart} -1`;
      });
      callback(null, lines.join(lineEnding));
    }
  });
};
exports.fixMyDumperTransform = fixMyDumperTransform;